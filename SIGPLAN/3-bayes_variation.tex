\section{A variant of bayesian algorithm}
\label{sec:design}
Based on Observation 1, the recent used Apps is more useful to predict next used Apps. However, the traditional bayesian algorithm\ref{eq: prediction} does not take the factor into account. The reason is that the training data at different time point is equally important for prediction accuracy in many application areas(e.g., Naive Bayes classifiers for e-mail filtering). In our variant of bayesian algorithm, we consider the different importance of different training data to predict.


In the traditional bayesian algorithm, the probability is calculated as in Equation~\ref{eq: prob}. A tuple $(A,C,D,H,L,Wf,U)$ represents a training data. To describe our variant of bayesian algorithm, we take $A,Wf$ for example. The expression $n(A,Wf)$ indicates the number of times that the training data tuple $(A,C,D,H,L,Wf,U)$ containing $A$ and $Wf$ at the same time occurs in the training set. $n(Wf)$ indicates the number of times that the training data tuple $(A,C,D,H,L,Wf,U)$ containing $Wf$ occurs in the training set. The ratio between $n(A,Wf)$ and $n(Wf)$ represents the posteriori probability $P(A|Wf)$ of launching a target application $A$ under the contextual information of $Wf$.


\begin{equation}
\footnotesize
\label{eq: prob}
    P(A|Wf)=\frac{n(A,Wf)}{n(Wf)}
\end{equation}


Considering the Observation 1, we assigns the records in the training set with different weights. Because recent contextual information play more important role to predict the usage of mobile Apps, recent records should be assigned with higher weights than ancient records. The Weighting Function we adopted is given in Equation~\ref{eq: weight}.


\begin{equation}
\footnotesize
\label{eq: weight}
    W_{i}=\frac{1}{(i+1)^s}
\end{equation}


The parameter $i$ indicates that the time of the records happened is on the $i_{th}$ preceding day from today. It means that, when $s=0$, all the records have the same weights. Thus, we need to modify the expression of the posteriori probability $P(A|Wf)$. And we use expression ${\hat P}(A|Wf)$ to indicate the new posteriori probability.


\begin{equation}
\footnotesize
\label{eq: new_prob}
    {\hat P}(A|Wf)=\frac{{\hat n}(A,Wf)}{{\hat n}(Wf)}
\end{equation}


\begin{equation}
\footnotesize
\label{eq: new_n}
    {\hat n}(A,Wf)=\sum_{j=1}^{N} W_{j,i}
\end{equation}


\begin{equation}
\footnotesize
\label{eq: new_n_comp}
    {\hat n}(A,Wf)=\sum_{j=1}^{N} W_{j,i} \times 1
\end{equation}


\begin{equation}
\footnotesize
\label{eq: weight_equation}
    W_{j,i}=W_{i}
\end{equation}


Equation~\ref{eq: new_n} is a simplified version of Equation~\ref{eq: new_n_comp}. To explain our algorithm clearly, we list Equation~\ref{eq: new_n_comp}. From Equation~\ref{eq: new_n_comp}, we can find that the traditional bayesian algorithm is the special case of our newly proposed algorithm where all the records in the training set have the same weight 1. Further the traditional bayesian algorithm sets scalar $1$ to the variable parameter $s$ actually.


In Equation~\ref{eq: new_n}, the variable $N$ counts total number of the records containing the contextual information $A$ and $Wf$ at the same time in the training set. The variable $W_{j,i}$ is the weight of $j_{th}$ records containing the contextual information $A$ and $Wf$ meanwhile. The subscript $i$ indicate thet the record happens on the $i_{th}$ preceding day from today. Thus, the value of the variable $W_{j,i}$ equals the variable $W_{i}$ just as Equation~\ref{eq: weight_equation}. And the calculation method of variable ${\hat n}(A,Wf)$ is the same.


Finally, we can use the new posteriori probability ${\hat p}$ to calculate the score of every App. The several other variable ${\hat P}(A | C)$, ${\hat P}(A|D,H,L)$ and ${\hat P}(A|U)$ have the same calculation method as variable ${\hat P}(A|W)$. Then according to how many Apps we need to predict, the top scored Apps are the final predictions.


\begin{equation}
\footnotesize
\label{eq: score}
    Socre(A) = {\hat P}(A | C) \times {\hat P}(A|D,H,L) \times {\hat P}(A|W) \times {\hat P}(A|U)
\end{equation}